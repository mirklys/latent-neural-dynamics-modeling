{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration (Unwrapped Script)\n",
    "\n",
    "This script demonstrates how to load and explore the multi-modal data from the Dareplane project.\n",
    "It follows the same logic as `1_data_loading_and_exploration.ipynb` but **unwraps all functions**\n",
    "into a sequential, linear script where each logical block is a cell.\n",
    "This allows for step-by-step execution and inspection of intermediate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path.cwd().parent.parent.joinpath(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This map is used to rename the raw channel names from the .mat file\n",
    "# to more human-readable names like 'LFP_1', 'ECOG_1', etc.\n",
    "CHANNEL_MAP = {\n",
    "    \"CECOG_HF_1___01___Array_1___01\": \"LFP_1\",\n",
    "    \"CECOG_HF_1___02___Array_1___02\": \"LFP_2\",\n",
    "    \"CECOG_HF_1___03___Array_1___03\": \"LFP_3\",\n",
    "    \"CECOG_HF_1___04___Array_1___04\": \"LFP_4\",\n",
    "    \"CECOG_HF_1___05___Array_1___05\": \"LFP_5\",\n",
    "    \"CECOG_HF_1___06___Array_1___06\": \"LFP_6\",\n",
    "    \"CECOG_HF_1___07___Array_1___07\": \"LFP_7\",\n",
    "    \"CECOG_HF_1___08___Array_1___08\": \"LFP_8\",\n",
    "    \"CECOG_HF_1___09___Array_2___09\": \"LFP_9\",\n",
    "    \"CECOG_HF_1___10___Array_2___10\": \"LFP_10\",\n",
    "    \"CECOG_HF_1___11___Array_2___11\": \"LFP_11\",\n",
    "    \"CECOG_HF_1___12___Array_2___12\": \"LFP_12\",\n",
    "    \"CECOG_HF_1___13___Array_2___13\": \"LFP_13\",\n",
    "    \"CECOG_HF_1___14___Array_2___14\": \"LFP_14\",\n",
    "    \"CECOG_HF_1___15___Array_2___15\": \"LFP_15\",\n",
    "    \"CECOG_HF_1___16___Array_2___16\": \"LFP_16\",\n",
    "    \"CECOG_HF_2___01___Array_3___01\": \"ECOG_1\",\n",
    "    \"CECOG_HF_2___02___Array_3___02\": \"ECOG_2\",\n",
    "    \"CECOG_HF_2___03___Array_3___03\": \"ECOG_3\",\n",
    "    \"CECOG_HF_2___04___Array_3___04\": \"ECOG_4\",\n",
    "    \"CECOG_HF_2___05___Array_3___05\": \"EOG_1\",\n",
    "    \"CECOG_HF_2___06___Array_3___06\": \"EOG_2\",\n",
    "    \"CECOG_HF_2___07___Array_3___07\": \"EOG_3\",\n",
    "    \"CECOG_HF_2___08___Array_3___08\": \"EOG_4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_path = DATA_ROOT.joinpath(\"sub-P001_ses-day2\", \"lsl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_xdf = list(\n",
    "    session_path.glob(\n",
    "        \"*block1_copydraw_off.xdf\"\n",
    "    )\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stem = fname_xdf.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_directory = fname_xdf.parents[1].joinpath(\"ao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all AO mat files that start with the file stem\n",
    "mat_files = list(ao_directory.glob(f\"{file_stem}*mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .mat file: /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day2/ao/block1_copydraw_off0001.mat\n"
     ]
    }
   ],
   "source": [
    "mat_file_path = mat_files[0]\n",
    "print(f\"Found .mat file: {mat_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = loadmat(mat_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_channel_name = \"CECOG_HF_2___01___Array_3___01\"\n",
    "ref_channel_data = mat_data[ref_channel_name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The sampling rate is stored in a variable like '..._KHz'.\n",
    "# It's given in KHz, so we multiply by 1000.\n",
    "sfreq = int(mat_data[f\"{ref_channel_name}_KHz\"][0][0]) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency: 22000 Hz\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sampling frequency: {sfreq} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame for AO (neural) data.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1208305 entries, 0 to 1208304\n",
      "Data columns (total 26 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   time    1208305 non-null  float64\n",
      " 1   src     1208305 non-null  object \n",
      " 2   LFP_1   1208305 non-null  int16  \n",
      " 3   LFP_2   1208305 non-null  int16  \n",
      " 4   LFP_3   1208305 non-null  int16  \n",
      " 5   LFP_4   1208305 non-null  int16  \n",
      " 6   LFP_5   1208305 non-null  int16  \n",
      " 7   LFP_6   1208305 non-null  int16  \n",
      " 8   LFP_7   1208305 non-null  int16  \n",
      " 9   LFP_8   1208305 non-null  int16  \n",
      " 10  LFP_9   1208305 non-null  int16  \n",
      " 11  LFP_10  1208305 non-null  int16  \n",
      " 12  LFP_11  1208305 non-null  int16  \n",
      " 13  LFP_12  1208305 non-null  int16  \n",
      " 14  LFP_13  1208305 non-null  int16  \n",
      " 15  LFP_14  1208305 non-null  int16  \n",
      " 16  LFP_15  1208305 non-null  int16  \n",
      " 17  LFP_16  1208305 non-null  int16  \n",
      " 18  ECOG_1  1208305 non-null  int16  \n",
      " 19  ECOG_2  1208305 non-null  int16  \n",
      " 20  ECOG_3  1208305 non-null  int16  \n",
      " 21  ECOG_4  1208305 non-null  int16  \n",
      " 22  EOG_1   1208305 non-null  int16  \n",
      " 23  EOG_2   1208305 non-null  int16  \n",
      " 24  EOG_3   1208305 non-null  int16  \n",
      " 25  EOG_4   1208305 non-null  int16  \n",
      "dtypes: float64(1), int16(24), object(1)\n",
      "memory usage: 73.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a time vector in seconds.\n",
    "num_samples = len(ref_channel_data)\n",
    "duration_sec = num_samples / sfreq\n",
    "time_vector = np.linspace(0, duration_sec, num_samples, endpoint=False)\n",
    "\n",
    "# Create the initial DataFrame for the AlphaOmega (AO) neural data.\n",
    "df_ao = pd.DataFrame({\"time\": time_vector, \"src\": \"AO\"})\n",
    "\n",
    "# Add all the channels defined in CHANNEL_MAP to the DataFrame.\n",
    "channel_data_dict = {v: mat_data[k][0] for k, v in CHANNEL_MAP.items()}\n",
    "df_ao = df_ao.assign(**channel_data_dict)\n",
    "\n",
    "print(\"Created DataFrame for AO (neural) data.\")\n",
    "df_ao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 6 hardware markers to the 'marker' column.\n",
      "Marker summary:\n",
      " marker\n",
      "34.0     2\n",
      "10.0     1\n",
      "110.0    1\n",
      "11.0     1\n",
      "111.0    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The CPORT stream contains hardware markers sent via a parallel port.\n",
    "# It's a 2xN array: row 0 is timestamps, row 1 is marker values.\n",
    "cport_data = mat_data[\"CPORT__1\"]\n",
    "cport_timestamps = cport_data[0]\n",
    "cport_values = cport_data[1]\n",
    "\n",
    "# The timestamps need to be converted to sample indices in our main data array.\n",
    "cport_khz = mat_data[\"CPORT__1_KHz\"][0][0]\n",
    "t_start_recording = mat_data[f\"{ref_channel_name}_TimeBegin\"][0][0]\n",
    "\n",
    "# Convert CPORT timestamps to seconds and align with the recording start time.\n",
    "cport_time_sec = (cport_timestamps / (int(cport_khz) * 1000)) - int(t_start_recording)\n",
    "\n",
    "# Convert aligned time in seconds to sample indices.\n",
    "cport_indices = (cport_time_sec * sfreq).astype(int).flatten()\n",
    "\n",
    "# Ignore markers with a value of 0 (hardware reset signals).\n",
    "valid_marker_mask = cport_values != 0\n",
    "valid_indices = cport_indices[valid_marker_mask]\n",
    "valid_values = cport_values[valid_marker_mask]\n",
    "\n",
    "# Add them to a new 'marker' column in the DataFrame.\n",
    "valid_indices_in_bounds = valid_indices[\n",
    "    (valid_indices >= 0) & (valid_indices < len(df_ao))\n",
    "]\n",
    "valid_values_in_bounds = valid_values[\n",
    "    (valid_indices >= 0) & (valid_indices < len(df_ao))\n",
    "]\n",
    "df_ao[\"marker\"] = np.nan  # Initialize column\n",
    "df_ao.loc[valid_indices_in_bounds, \"marker\"] = valid_values_in_bounds\n",
    "\n",
    "print(f\"Added {len(valid_indices_in_bounds)} hardware markers to the 'marker' column.\")\n",
    "print(\"Marker summary:\\n\", df_ao[\"marker\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSL data streams from: /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day2/lsl/block1_copydraw_off.xdf\n"
     ]
    }
   ],
   "source": [
    "import pyxdf\n",
    "print(f\"Loading LSL data streams from: {fname_xdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "streams, header = pyxdf.load_xdf(fname_xdf, dejitter_timestamps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao_lsl_stream = next((s for s in streams if \"AODataStream\" in s[\"info\"][\"name\"][0]), None)\n",
    "marker_stream = next((s for s in streams if \"CopyDrawParadigmMarkerStream\" in s[\"info\"][\"name\"][0]), None)\n",
    "stylus_stream = next((s for s in streams if \"Mouse\" in s[\"info\"][\"name\"][0]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ao_lsl_stream is None or marker_stream is None:\n",
    "    raise ValueError(\"Could not find AODataStream or MarkerStream in the XDF file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame for LSL signal data (df_lsl).\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Create the LSL signal DataFrame (df_lsl) ---\n",
    "# The LSL signal is also recorded from the ECoG channels. We'll use the first ECoG channel (index 16) for alignment.\n",
    "lsl_ecog_channel_index = 16 \n",
    "df_lsl = pd.DataFrame({\n",
    "    \"time\": ao_lsl_stream[\"time_stamps\"],\n",
    "    \"data\": ao_lsl_stream[\"time_series\"][:, lsl_ecog_channel_index],\n",
    "    \"src\": \"LSL\"\n",
    "})\n",
    "# The LSL timestamps are absolute. We make them relative to their own start time for now.\n",
    "# The alignment logic will calculate the true offset relative to the AO data later.\n",
    "t0_lsl = df_lsl[\"time\"].iloc[0]\n",
    "df_lsl[\"time\"] -= t0_lsl\n",
    "print(\"Created DataFrame for LSL signal data (df_lsl).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame for LSL markers (df_markers).\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Create the LSL marker DataFrame (df_markers) ---\n",
    "df_markers = pd.DataFrame({\n",
    "    \"time\": marker_stream[\"time_stamps\"],\n",
    "    \"marker\": [m[0] for m in marker_stream[\"time_series\"]]\n",
    "})\n",
    "df_markers[\"time\"] -= t0_lsl # Align marker timestamps to the start of the LSL signal stream\n",
    "print(\"Created DataFrame for LSL markers (df_markers).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylus_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released'],\n",
       " ['MouseButtonLeft pressed'],\n",
       " ['MouseButtonLeft released']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stylus_stream[\"time_series\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A stylus-related stream named 'MouseButtons' was found, but it does not contain (x, y) coordinates.\n",
      "This is likely the button-press stream. Skipping creation of df_stylus.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Create the stylus DataFrame (df_stylus) ---\n",
    "if stylus_stream:\n",
    "    # The stylus coordinate stream should have 2 columns of data (x, y).\n",
    "    # The 'MouseButtons' stream, which was likely picked up, has only 1 column of string data.\n",
    "    # We check the shape of the time_series to ensure we have the correct stream.\n",
    "    is_coordinate_stream = (\n",
    "        isinstance(stylus_stream[\"time_series\"], list) and\n",
    "        len(stylus_stream[\"time_series\"]) > 0 and\n",
    "        len(stylus_stream[\"time_series\"][0]) == 2 and\n",
    "        isinstance(stylus_stream[\"time_series\"][0][0], (int, float))\n",
    "    )\n",
    "\n",
    "    if is_coordinate_stream:\n",
    "        df_stylus = pd.DataFrame(stylus_stream[\"time_series\"], columns=[\"x\", \"y\"])\n",
    "        df_stylus[\"time\"] = stylus_stream[\"time_stamps\"]\n",
    "        df_stylus[\"time\"] -= t0_lsl # Align stylus timestamps to the start of the LSL signal stream\n",
    "        print(\"Created DataFrame for stylus data (df_stylus).\")\n",
    "    else:\n",
    "        # This is likely the 'MouseButtons' stream, not the coordinate stream.\n",
    "        print(f\"A stylus-related stream named '{stylus_stream['info']['name'][0]}' was found, but it does not contain (x, y) coordinates.\")\n",
    "        print(\"This is likely the button-press stream. Skipping creation of df_stylus.\")\n",
    "        df_stylus = None\n",
    "else:\n",
    "    df_stylus = None\n",
    "    print(\"Stylus stream not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added LSL markers to df_lsl.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999144 entries, 0 to 999143\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   time    999144 non-null  float64\n",
      " 1   data    999144 non-null  float32\n",
      " 2   src     999144 non-null  object \n",
      " 3   marker  6 non-null       float64\n",
      "dtypes: float32(1), float64(2), object(1)\n",
      "memory usage: 26.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Add LSL markers to the LSL signal DataFrame for the fallback alignment method ---\n",
    "lsl_marker_indices = [np.searchsorted(df_lsl.time, t) for t in df_markers.time]\n",
    "df_lsl[\"marker\"] = np.nan\n",
    "# Ensure indices are within bounds of the dataframe\n",
    "valid_marker_mask = [idx < len(df_lsl) for idx in lsl_marker_indices]\n",
    "valid_indices = np.array(lsl_marker_indices)[valid_marker_mask]\n",
    "valid_values = df_markers.marker.values[valid_marker_mask]\n",
    "df_lsl.loc[valid_indices, \"marker\"] = valid_values\n",
    "print(\"Added LSL markers to df_lsl.\")\n",
    "df_lsl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cell 7: Aligning AO and LSL data streams.\n",
      "Attempting alignment using hardware markers...\n",
      "Marker alignment failed ('No matching marker time differences found.'). Falling back to stim artifact alignment.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match_found:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo matching marker time differences found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     36\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound matching marker sequence starting at AO marker index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mao_start_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'No matching marker time differences found.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     68\u001b[39m threshold = \u001b[32m2000\u001b[39m  \u001b[38;5;66;03m# uV, for detecting the large stimulation artifact\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Find the index of the first major peak (the stim artifact) in both streams\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# We start searching after 1s to avoid startup artifacts.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m ix_lsl_first_peak = \u001b[43mdf_lsl\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_lsl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_lsl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     73\u001b[39m ix_ao_first_peak = df_ao[(df_ao.ECOG_1 > threshold) & (df_ao.time > \u001b[32m1\u001b[39m)].index[\u001b[32m0\u001b[39m]\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Calculate the coarse time offset between the two streams\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/indexes/base.py:5401\u001b[39m, in \u001b[36mIndex.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   5398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[32m   5399\u001b[39m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[32m   5400\u001b[39m     key = com.cast_scalar_indexer(key)\n\u001b[32m-> \u001b[39m\u001b[32m5401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   5404\u001b[39m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[32m   5405\u001b[39m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[32m   5406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_slice(key)\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# This cell unwraps the logic from `align_on_markers` and `align_on_stim_artifact`.\n",
    "# It first tries to align using hardware markers, and if that fails, it falls\n",
    "# back to using the large stimulation artifact.\n",
    "\n",
    "print(\"\\nCell 7: Aligning AO and LSL data streams.\")\n",
    "aligned_df = None\n",
    "time_offset = None\n",
    "\n",
    "# --- Method 1: Align on Hardware Markers (unwrapped from `align_on_markers`) ---\n",
    "try:\n",
    "    print(\"Attempting alignment using hardware markers...\")\n",
    "    # Get the timestamps of non-null markers from both sources\n",
    "    ao_marker_times = df_ao[df_ao.marker.notna()].time\n",
    "    lsl_marker_times = df_markers[df_markers.marker.notna()].time\n",
    "\n",
    "    # Calculate the time difference (delta) between consecutive markers\n",
    "    dt_ao = np.diff(ao_marker_times)\n",
    "    dt_lsl = np.diff(lsl_marker_times)\n",
    "\n",
    "    # Find a matching sequence of marker intervals. This is needed because\n",
    "    # the AO recording might have extra hardware triggers at the start.\n",
    "    # We look for a sequence in AO deltas that matches the first LSL delta.\n",
    "    match_found = False\n",
    "    ao_start_index = -1\n",
    "    for i in range(min(3, len(dt_ao))):  # Check first 3 AO deltas\n",
    "        # Allow for a 10% tolerance in timing\n",
    "        if np.abs(dt_ao[i] - dt_lsl[0]) / dt_lsl[0] < 0.1:\n",
    "            ao_start_index = i\n",
    "            match_found = True\n",
    "            break\n",
    "\n",
    "    if not match_found:\n",
    "        raise KeyError(\"No matching marker time differences found.\")\n",
    "\n",
    "    print(\n",
    "        f\"Found matching marker sequence starting at AO marker index {ao_start_index}.\"\n",
    "    )\n",
    "\n",
    "    # --- Transfer LSL markers to the AO timeline ---\n",
    "    # Get the time of the first matched AO marker\n",
    "    t0_ao = ao_marker_times.iloc[ao_start_index]\n",
    "\n",
    "    # The times of all subsequent LSL markers relative to the first one\n",
    "    lsl_marker_relative_times = lsl_marker_times - lsl_marker_times.iloc[0]\n",
    "\n",
    "    # Calculate the absolute timestamps for LSL markers in the AO time domain\n",
    "    aligned_lsl_marker_times = t0_ao + lsl_marker_relative_times\n",
    "\n",
    "    # Find the closest sample index in the AO dataframe for each aligned marker time\n",
    "    aligned_indices = [np.searchsorted(df_ao.time, t) for t in aligned_lsl_marker_times]\n",
    "\n",
    "    # Create the new 'lsl_marker' column in the AO dataframe\n",
    "    aligned_df = df_ao.copy()\n",
    "    aligned_df[\"lsl_marker\"] = np.nan\n",
    "    aligned_df.loc[aligned_indices, \"lsl_marker\"] = df_markers[\n",
    "        df_markers.marker.notna()\n",
    "    ].marker.values\n",
    "\n",
    "    # For visualization, calculate the time offset\n",
    "    time_offset = ao_marker_times.iloc[ao_start_index] - lsl_marker_times.iloc[0]\n",
    "\n",
    "    print(\n",
    "        f\"Success: Aligned data using hardware markers. Time offset: {time_offset:.4f}s\"\n",
    "    )\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(f\"Marker alignment failed ({e}). Falling back to stim artifact alignment.\")\n",
    "\n",
    "    threshold = 2000  # uV, for detecting the large stimulation artifact\n",
    "\n",
    "    # Find the index of the first major peak (the stim artifact) in both streams\n",
    "    # We start searching after 1s to avoid startup artifacts.\n",
    "    ix_lsl_first_peak = df_lsl[(df_lsl.data > threshold) & (df_lsl.time > 1)].index[0]\n",
    "    ix_ao_first_peak = df_ao[(df_ao.ECOG_1 > threshold) & (df_ao.time > 1)].index[0]\n",
    "\n",
    "    # Calculate the coarse time offset between the two streams\n",
    "    coarse_time_offset = (\n",
    "        df_ao.time.iloc[ix_ao_first_peak] - df_lsl.time.iloc[ix_lsl_first_peak]\n",
    "    )\n",
    "    print(f\"Coarse offset from stim artifact: {coarse_time_offset:.4f}s\")\n",
    "\n",
    "    # --- Fine-tune the offset with a small cross-correlation ---\n",
    "    # This corrects for small misalignments by matching the signal shape.\n",
    "    chk_idx_range = 10_000  # Search window in samples (in AO data)\n",
    "    chk_len = 400  # Length of the signal chunk to match (in LSL data)\n",
    "\n",
    "    # We'll match the signal shape around the first LSL marker\n",
    "    idx_lsl_first_marker = df_lsl[df_lsl.marker.notna()].index[0]\n",
    "    t_lsl_first_marker = df_lsl.time.iloc[idx_lsl_first_marker]\n",
    "\n",
    "    # Estimate where this marker should be in the AO data using the coarse offset\n",
    "    ao_test_idx = np.searchsorted(df_ao.time, t_lsl_first_marker + coarse_time_offset)\n",
    "\n",
    "    # Extract the chunk of LSL data to be used as a template\n",
    "    dlsl_chk = df_lsl.iloc[idx_lsl_first_marker : idx_lsl_first_marker + chk_len]\n",
    "\n",
    "    # Extract a larger search window from the AO data\n",
    "    dao_chk = df_ao.iloc[ao_test_idx - chk_idx_range : ao_test_idx + chk_idx_range]\n",
    "\n",
    "    # Slide the LSL chunk across the AO window and find the best match\n",
    "    differences = np.asarray(\n",
    "        [\n",
    "            np.abs(\n",
    "                dao_chk.iloc[i : i + chk_len].ECOG_1.values - dlsl_chk.data.values\n",
    "            ).mean()\n",
    "            for i in range(len(dao_chk) - chk_len)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # The shift that minimizes the difference\n",
    "    idx_shift = np.argmin(differences) - chk_idx_range\n",
    "    fine_tuned_offset = coarse_time_offset + idx_shift / sfreq\n",
    "    time_offset = fine_tuned_offset  # Store for visualization\n",
    "    print(f\"Fine-tuned offset after cross-correlation: {fine_tuned_offset:.4f}s\")\n",
    "\n",
    "    # --- Transfer LSL markers to the AO timeline using the final offset ---\n",
    "    dm = df_markers[df_markers.marker.notna()]\n",
    "    aligned_indices = [\n",
    "        np.searchsorted(df_ao.time, t + fine_tuned_offset) for t in dm.time\n",
    "    ]\n",
    "\n",
    "    aligned_df = df_ao.copy()\n",
    "    aligned_df[\"lsl_marker\"] = np.nan\n",
    "    aligned_df.loc[aligned_indices, \"lsl_marker\"] = dm.marker.values\n",
    "\n",
    "    print(\"Success: Aligned data using stimulation artifact.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if aligned_df is not None:\n",
    "    print(f\"Alignment complete. Result is a DataFrame with shape {aligned_df.shape}\")\n",
    "    print(\n",
    "        f\"Found {aligned_df.lsl_marker.notna().sum()} LSL markers now aligned to the AO data.\"\n",
    "    )\n",
    "    print(\"\\nValue counts of aligned markers:\")\n",
    "    print(aligned_df.lsl_marker.value_counts())\n",
    "    print(\"\\nHead of the DataFrame with a marker:\")\n",
    "    print(aligned_df[aligned_df.lsl_marker.notna()].head())\n",
    "else:\n",
    "    print(\"Alignment failed. `aligned_df` is None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a crucial step to visually confirm the alignment worked. We plot\n",
    "# the LSL signal (shifted by the calculated offset) on top of the AO signal.\n",
    "# They should overlap almost perfectly.\n",
    "\n",
    "print(\"\\nCell 9: Visualizing the alignment quality.\")\n",
    "\n",
    "if time_offset is not None and aligned_df is not None:\n",
    "    # Create a new DataFrame for plotting LSL data with the aligned time\n",
    "    df_lsl_aligned = df_lsl.copy()\n",
    "    df_lsl_aligned[\"time\"] += time_offset\n",
    "\n",
    "    # Concatenate for easier plotting with Plotly Express\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            df_ao[[\"time\", \"ECOG_1\", \"src\"]],\n",
    "            df_lsl_aligned[[\"time\", \"data\", \"src\"]].rename(columns={\"data\": \"ECOG_1\"}),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Select a small time window to see the alignment clearly.\n",
    "    # Let's find the first marker to center the plot around.\n",
    "    first_marker_time = aligned_df[aligned_df.lsl_marker.notna()].time.iloc[0]\n",
    "    plot_window_start = first_marker_time - 0.5\n",
    "    plot_window_end = first_marker_time + 0.5\n",
    "\n",
    "    plot_df_window = plot_df[\n",
    "        (plot_df[\"time\"] >= plot_window_start) & (plot_df[\"time\"] <= plot_window_end)\n",
    "    ]\n",
    "\n",
    "    fig = px.line(\n",
    "        plot_df_window,\n",
    "        x=\"time\",\n",
    "        y=\"ECOG_1\",\n",
    "        color=\"src\",\n",
    "        title=\"Alignment Check: AO vs LSL (shifted)\",\n",
    "        labels={\"time\": \"Time (s)\", \"ECOG_1\": \"Amplitude (uV)\"},\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Skipping alignment visualization because alignment failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCell 10: Visualizing the stylus trace.\")\n",
    "\n",
    "# The stylus data is in the `df_stylus` DataFrame created in Cell 6.\n",
    "fig = px.line(df_stylus, x=\"x\", y=\"y\", title=\"Stylus Trace for the Block\")\n",
    "\n",
    "# Screen coordinates often have the origin at the top-left, so we invert the y-axis.\n",
    "fig.update_yaxes(autorange=\"reversed\")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(scaleanchor=\"y\", scaleratio=1)\n",
    ")  # Ensure aspect ratio is 1:1\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
