{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration\n",
    "\n",
    "This notebook demonstrates how to load and explore the multi-modal data from the Dareplane project. We will cover:\n",
    "\n",
    "- Loading XDF files for a single session.\n",
    "- Inspecting the `mne.Raw` object containing LFP, ECoG, and EOG data.\n",
    "- Visualizing the raw neural data and event markers.\n",
    "- Extracting and visualizing the stylus tracing coordinates from the behavioral data stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setup\n",
    "\n",
    "First, let's import the necessary libraries and add the `analysis_scripts` directory to our Python path to access the custom loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyxdf\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent / \"analysis_scripts\"))\n",
    "\n",
    "from load_xdf import create_raws_from_mat_and_xdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Neural Data\n",
    "\n",
    "Now, we'll load the data for a specific session. The `get_xdf_files` function helps us find the relevant XDF files, and `create_raws_from_mat_and_xdf` loads the data into a list of `mne.Raw` objects, one for each block in the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAP = {\n",
    "    \"CECOG_HF_1___01___Array_1___01\": \"LFP_1\",\n",
    "    \"CECOG_HF_1___02___Array_1___02\": \"LFP_2\",\n",
    "    \"CECOG_HF_1___03___Array_1___03\": \"LFP_3\",\n",
    "    \"CECOG_HF_1___04___Array_1___04\": \"LFP_4\",\n",
    "    \"CECOG_HF_1___05___Array_1___05\": \"LFP_5\",\n",
    "    \"CECOG_HF_1___06___Array_1___06\": \"LFP_6\",\n",
    "    \"CECOG_HF_1___07___Array_1___07\": \"LFP_7\",\n",
    "    \"CECOG_HF_1___08___Array_1___08\": \"LFP_8\",\n",
    "    \"CECOG_HF_1___09___Array_2___09\": \"LFP_9\",\n",
    "    \"CECOG_HF_1___10___Array_2___10\": \"LFP_10\",\n",
    "    \"CECOG_HF_1___11___Array_2___11\": \"LFP_11\",\n",
    "    \"CECOG_HF_1___12___Array_2___12\": \"LFP_12\",\n",
    "    \"CECOG_HF_1___13___Array_2___13\": \"LFP_13\",\n",
    "    \"CECOG_HF_1___14___Array_2___14\": \"LFP_14\",\n",
    "    \"CECOG_HF_1___15___Array_2___15\": \"LFP_15\",\n",
    "    \"CECOG_HF_1___16___Array_2___16\": \"LFP_16\",\n",
    "    \"CECOG_HF_2___01___Array_3___01\": \"ECOG_1\",\n",
    "    \"CECOG_HF_2___02___Array_3___02\": \"ECOG_2\",\n",
    "    \"CECOG_HF_2___03___Array_3___03\": \"ECOG_3\",\n",
    "    \"CECOG_HF_2___04___Array_3___04\": \"ECOG_4\",\n",
    "    \"CECOG_HF_2___05___Array_3___05\": \"EOG_1\",\n",
    "    \"CECOG_HF_2___06___Array_3___06\": \"EOG_2\",\n",
    "    \"CECOG_HF_2___07___Array_3___07\": \"EOG_3\",\n",
    "    \"CECOG_HF_2___08___Array_3___08\": \"EOG_4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = str(Path.cwd().parent.parent)\n",
    "DATA_PATH = os.path.join(ROOT_PATH, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdf_files(day: str = \"day3\", paradigms: str = \"lsl\") -> list:\n",
    "    directory = f\"{DATA_PATH}/sub-P001_ses-{day}/{paradigms}/\"\n",
    "    return [\n",
    "        os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".xdf\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf_files = get_xdf_files(day=\"day3\", paradigms=\"lsl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AO_file_data(fname: Path) -> dict:\n",
    "    \"\"\"Finds and loads the .mat file corresponding to an .xdf file.\"\"\"\n",
    "    stem = fname.stem\n",
    "    pp = fname.parents[1].joinpath(\"AO\")\n",
    "    files = list(pp.glob(f\"{stem}*mat\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .mat file found for {fname.name}\")\n",
    "    return {f: loadmat(f) for f in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AO_data(fname, with_cport_marker: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the high-quality, uninterrupted neural data from the Neuro Omega .mat file.\n",
    "    This is the \"ground truth\" for the neural signal.\n",
    "    \"\"\"\n",
    "    d = get_AO_file_data(fname)\n",
    "    data = d[list(d.keys())[-1]]\n",
    "    dm = data[\"CECOG_HF_2___01___Array_3___01\"][0]\n",
    "    tstart = data[\"CECOG_HF_2___01___Array_3___01_TimeBegin\"][0]\n",
    "    tm = np.linspace(0, int(len(dm) / 22_000), len(dm))\n",
    "    df = pd.DataFrame({\"time\": tm, \"data\": dm, \"src\": \"AO\"})\n",
    "    df = df.assign(**{v: data[k][0] for k, v in CHANNEL_MAP.items()})\n",
    "\n",
    "    if with_cport_marker and \"CPORT__1\" in data:\n",
    "        cport_ix = (\n",
    "            ((data[\"CPORT__1\"][0] / (data[\"CPORT__1_KHz\"] * 1000) - tstart) * 22_000)\n",
    "            .astype(int)\n",
    "            .flatten()\n",
    "        )\n",
    "        marker = data[\"CPORT__1\"][1]\n",
    "        df.loc[cport_ix[marker != 0], \"marker\"] = marker[marker != 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdf_data(fname) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads the LSL data from the .xdf file, which contains the (potentially gappy)\n",
    "    neural signal stream and the accurate experimental event markers.\n",
    "    \"\"\"\n",
    "    xdf_data, _ = pyxdf.load_xdf(fname, dejitter_timestamps=False)\n",
    "    streams = {d[\"info\"][\"name\"][0]: d for d in xdf_data}\n",
    "\n",
    "    ao_stream = streams[\"AODataStream\"]\n",
    "    marker_stream = streams[\"CopyDrawParadigmMarkerStream\"]\n",
    "\n",
    "    # Create DataFrame for the LSL neural data\n",
    "    dx = ao_stream[\"time_series\"][:, 16]  # Using ECOG_1 as reference signal\n",
    "    tx = ao_stream[\"time_stamps\"]\n",
    "    df_lsl = pd.DataFrame({\"time\": tx, \"data\": dx, \"src\": \"LSL\"}).sort_values(\"time\")\n",
    "\n",
    "    # Add markers to the LSL DataFrame\n",
    "    m_times = marker_stream[\"time_stamps\"]\n",
    "    m_series = marker_stream[\"time_series\"][:, 0]\n",
    "\n",
    "    # Align markers to the closest timestamp in the LSL neural data\n",
    "    ix_marker = [np.argmin(np.abs(df_lsl.time - v)) for v in m_times]\n",
    "    df_lsl.loc[ix_marker, \"marker\"] = m_series\n",
    "\n",
    "    # Normalize time to start at 0\n",
    "    tmin = df_lsl.time.iloc[0]\n",
    "    df_lsl.time -= tmin\n",
    "\n",
    "    # Create a separate, clean DataFrame for just the markers and their precise timestamps\n",
    "    df_markers = pd.DataFrame({\"time\": m_times, \"marker\": m_series})\n",
    "    df_markers.time -= tmin\n",
    "\n",
    "    return df_lsl, df_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_on_markers(dfao: pd.DataFrame, dts: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aligns AO and LSL data by matching the time intervals between hardware markers.\n",
    "    This is the preferred method when reliable hardware markers exist in the .mat file.\n",
    "    \"\"\"\n",
    "    dt_lsl = np.diff(dts[dts.marker.notna()].time)\n",
    "    dt_ao = np.diff(dfao[dfao.marker.notna()].time)\n",
    "\n",
    "    # Find a matching sequence of marker intervals\n",
    "    ii = None\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if np.abs(dt_ao[i : i + j + 1].sum() - dt_lsl[0]) / dt_ao[0] < 0.1:\n",
    "                ii = i if ii is None else ii\n",
    "    if ii is None:\n",
    "        raise KeyError(\"No matching marker distances found\")\n",
    "\n",
    "    # Transfer LSL markers to the AO timeline\n",
    "    dists = dt_lsl.cumsum()\n",
    "    t0idx = dfao[dfao.marker.notna()].index[ii]\n",
    "    t0 = dfao.time.iloc[t0idx]\n",
    "    idx = [t0idx] + [np.searchsorted(dfao.time, t0 + v) for v in dists]\n",
    "    dfao[\"lsl_marker\"] = np.nan\n",
    "    dfao.loc[idx, \"lsl_marker\"] = dts[dts.marker.notna()].marker.values\n",
    "    return dfao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_on_stim_artifact(\n",
    "    dfao: pd.DataFrame, dflsl: pd.DataFrame, threshold: float = 2000\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fallback alignment method. Aligns data by finding the first large stimulation\n",
    "    artifact peak present in both the AO and LSL signals.\n",
    "    \"\"\"\n",
    "    # Find the index of the first major peak (the stim artifact)\n",
    "    ix_lsl_first_peak = dflsl[(dflsl.data > threshold) & (dflsl.time > 1)].index[0]\n",
    "    ix_ao_first_peak = dfao[(dfao.data > threshold) & (dfao.time > 1)].index[0]\n",
    "\n",
    "    # Calculate the time offset between the two streams\n",
    "    time_offset = (\n",
    "        dfao.iloc[ix_ao_first_peak][\"time\"] - dflsl.iloc[ix_lsl_first_peak][\"time\"]\n",
    "    )\n",
    "\n",
    "    # Fine-tune the offset with a small cross-correlation\n",
    "    chk_idx_range = 10_000\n",
    "    chk_len = 400\n",
    "    idx_lsl_first_marker_idx = dflsl[dflsl.marker.notna()].index[0]\n",
    "    t_lsl_first_marker = dflsl.iloc[idx_lsl_first_marker_idx].time\n",
    "    ao_test_idx = np.searchsorted(dfao.time, t_lsl_first_marker + time_offset)\n",
    "    dao_chk = dfao.iloc[ao_test_idx - chk_idx_range : ao_test_idx + chk_idx_range]\n",
    "    dlsl_chk = dflsl[idx_lsl_first_marker_idx : idx_lsl_first_marker_idx + chk_len]\n",
    "    differences = np.asarray(\n",
    "        [\n",
    "            dao_chk.iloc[i : i + chk_len].data.values - dlsl_chk.data.values\n",
    "            for i in range(2 * chk_idx_range - chk_len)\n",
    "        ]\n",
    "    )\n",
    "    idx_shift = np.argmin(np.abs(differences).mean(axis=1)) - chk_idx_range\n",
    "    fine_tuned_offset = time_offset + idx_shift / 22_000\n",
    "\n",
    "    # Transfer LSL markers to the AO timeline using the calculated offset\n",
    "    dm = dflsl[dflsl.marker.notna()]\n",
    "    idx = [np.searchsorted(dfao.time, v + fine_tuned_offset) for v in dm.time]\n",
    "    dfao[\"lsl_marker\"] = np.nan\n",
    "    dfao.loc[idx, \"lsl_marker\"] = dflsl[dflsl.marker.notna()].marker.values\n",
    "    return dfao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Loaded LSL data with 36 markers from .xdf\n"
     ]
    }
   ],
   "source": [
    "df_lsl, df_markers = get_xdf_data(xdf_files[0])\n",
    "print(f\"  - Loaded LSL data with {len(df_markers)} markers from .xdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No .mat file found for block4_copydraw_on.xdf\n"
     ]
    }
   ],
   "source": [
    "path_object = Path(xdf_files[0])\n",
    "try:\n",
    "    df_ao = get_AO_data(path_object, with_cport_marker=True)\n",
    "    print(\n",
    "        f\"  - Loaded complete neural signal from .mat with {df_ao.marker.notna().sum()} hardware markers.\"\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1b. Aligning the two data streams...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_ao' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m aligned_ao_data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# First, try to align using the hardware markers. This is most reliable.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     aligned_ao_data = align_on_markers(\u001b[43mdf_ao\u001b[49m.copy(), df_markers)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  - Success: Aligned data using hardware markers.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# If marker alignment fails (e.g., no markers in .mat file), fall back\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# to aligning on the large DBS stimulation artifact.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_ao' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1b. Align the two data streams\n",
    "print(\"\\n1b. Aligning the two data streams...\")\n",
    "aligned_ao_data = None\n",
    "try:\n",
    "    # First, try to align using the hardware markers. This is most reliable.\n",
    "    aligned_ao_data = align_on_markers(df_ao.copy(), df_markers)\n",
    "    print(\"  - Success: Aligned data using hardware markers.\")\n",
    "except (KeyError, IndexError) as e:\n",
    "    # If marker alignment fails (e.g., no markers in .mat file), fall back\n",
    "    # to aligning on the large DBS stimulation artifact.\n",
    "    print(\n",
    "        f\"  - Marker alignment failed ({e}). Falling back to stim artifact alignment.\"\n",
    "    )\n",
    "    # Reload AO data without expecting markers, just in case\n",
    "    df_ao_no_marker = get_AO_data(file_to_process, with_cport_marker=False)\n",
    "    aligned_ao_data = align_on_stim_artifact(df_ao_no_marker.copy(), df_lsl)\n",
    "    print(\"  - Success: Aligned data using stimulation artifact.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, `aligned_ao_data` is a pandas DataFrame containing the\n",
    "# complete, high-quality neural signal, now with a new 'lsl_marker'\n",
    "# column that has the correct event timings.\n",
    "print(f\"\\nAlignment complete. Result is a DataFrame with shape {aligned_ao_data.shape}\")\n",
    "print(\n",
    "    f\"Found {aligned_ao_data.lsl_marker.notna().sum()} LSL markers now aligned to the AO data.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Create an MNE Raw Object ---\n",
    "print(\"\\n--- Step 2: Converting aligned data to an MNE Raw object ---\")\n",
    "\n",
    "# 2a. Define the metadata for the MNE object\n",
    "ch_names = [c for c in aligned_ao_data.columns if c.startswith((\"LFP\", \"ECOG\", \"EOG\"))]\n",
    "ch_types = (\n",
    "    [\"dbs\"] * 16  # 16 LFP channels are considered 'dbs' type\n",
    "    + [\"ecog\"] * 4  # 4 ECoG channels\n",
    "    + [\"eog\"] * 4  # 4 EOG channels\n",
    ")\n",
    "sfreq = 22000  # The original sampling frequency of the Neuro Omega system\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "print(f\"  - Created MNE Info object for {len(ch_names)} channels at {sfreq} Hz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Extract data and convert from microvolts to volts (MNE standard)\n",
    "neural_data_uV = aligned_ao_data[ch_names].to_numpy().T\n",
    "neural_data_V = neural_data_uV * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c. Create the MNE RawArray object\n",
    "raw = mne.io.RawArray(neural_data_V, info)\n",
    "raw._filenames = [file_to_process.name]\n",
    "print(\"  - Created MNE RawArray object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d. Create and attach the annotations from our aligned markers\n",
    "marker_df = aligned_ao_data[aligned_ao_data.lsl_marker.notna()]\n",
    "onsets = marker_df.index / sfreq  # Onset time in seconds\n",
    "durations = np.zeros_like(onsets)  # Duration is 0 for point-like events\n",
    "descriptions = marker_df.lsl_marker.astype(str)\n",
    "annotations = mne.Annotations(\n",
    "    onset=onsets, duration=durations, description=descriptions\n",
    ")\n",
    "raw.set_annotations(annotations)\n",
    "print(f\"  - Attached {len(annotations)} annotations to the Raw object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Resample the Data ---\n",
    "print(\"\\n--- Step 3: Resampling data to 300 Hz ---\")\n",
    "resample_freq = 300\n",
    "raw.resample(resample_freq)\n",
    "print(f\"Resampling complete. New sampling frequency: {raw.info['sfreq']} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Inspection ---\n",
    "print(\"\\n--- Data loading and initial preparation finished! ---\")\n",
    "print(\"You can now analyze the 'raw' object.\")\n",
    "\n",
    "print(\"\\nInfo for the processed data block:\")\n",
    "print(raw.info)\n",
    "\n",
    "print(\"\\nAnnotations (event markers) for the block:\")\n",
    "print(raw.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to visually inspect it.\n",
    "print(\"\\nPlotting the first 30s of ECoG data...\")\n",
    "ecog_channels = [ch for ch in raw.ch_names if \"ECOG\" in ch]\n",
    "raw.copy().pick(ecog_channels).plot(\n",
    "    duration=30, start=0, n_channels=len(ecog_channels), scalings=\"auto\"\n",
    ")\n",
    "print(\"Plot window opened. Close it to continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block4_copydraw_on.xdf\n",
      "Failed for /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block4_copydraw_on.xdf: 'str' object has no attribute 'stem'\n",
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block3_copydraw_off.xdf\n",
      "Failed for /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block3_copydraw_off.xdf: 'str' object has no attribute 'stem'\n",
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block12_copydraw_on.xdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found likely XDF file corruption (unpack requires a buffer of 8 bytes), scanning forward to next boundary chunk.\n",
      "found likely XDF file corruption (unpack requires a buffer of 8 bytes), scanning forward to next boundary chunk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block12_copydraw_on.xdf: 'str' object has no attribute 'stem'\n",
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block6_copydraw_on.xdf\n",
      "Failed for /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block6_copydraw_on.xdf: 'str' object has no attribute 'stem'\n",
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block5_copydraw_off.xdf\n",
      "Failed for /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block5_copydraw_off.xdf: 'str' object has no attribute 'stem'\n",
      "Processing /home/bobby/repos/latent-neural-dynamics-modeling/data/sub-P001_ses-day3/lsl/block7_copydraw_off.xdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m raws = \u001b[43mcreate_raws_from_mat_and_xdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdf_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mday3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:1030\u001b[39m, in \u001b[36mcreate_raws_from_mat_and_xdf\u001b[39m\u001b[34m(files, day)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     ao_data.append(\u001b[43mget_AO_with_lsl_markers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1032\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:647\u001b[39m, in \u001b[36mget_AO_with_lsl_markers\u001b[39m\u001b[34m(fname, day)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_AO_with_lsl_markers\u001b[39m(fname, day: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mday4\u001b[39m\u001b[33m\"\u001b[39m) -> pd.DataFrame:\n\u001b[32m    644\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check if the first markers time differences agree, then align to\u001b[39;00m\n\u001b[32m    645\u001b[39m \u001b[33;03m    the LSL markers to the AO data\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     dflsl, dts = \u001b[43mget_xdf_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m day == \u001b[33m\"\u001b[39m\u001b[33mday3\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    650\u001b[39m         dfao = manual_alignment_day3(fname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:623\u001b[39m, in \u001b[36mget_xdf_data\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    621\u001b[39m cpm = xdf_data[streams.index(\u001b[33m\"\u001b[39m\u001b[33mCopyDrawParadigmMarkerStream\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    622\u001b[39m mmsk = cpm[\u001b[33m\"\u001b[39m\u001b[33mtime_stamps\u001b[39m\u001b[33m\"\u001b[39m] < tx.max()\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m ix_marker = \u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcpm\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtime_stamps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmmsk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    624\u001b[39m df.loc[ix_marker, \u001b[33m\"\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m\"\u001b[39m] = cpm[\u001b[33m\"\u001b[39m\u001b[33mtime_series\u001b[39m\u001b[33m\"\u001b[39m][mmsk, \u001b[32m0\u001b[39m]\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# markers only if left over (in case the LFP/ECOG data stream aborted)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:623\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    621\u001b[39m cpm = xdf_data[streams.index(\u001b[33m\"\u001b[39m\u001b[33mCopyDrawParadigmMarkerStream\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    622\u001b[39m mmsk = cpm[\u001b[33m\"\u001b[39m\u001b[33mtime_stamps\u001b[39m\u001b[33m\"\u001b[39m] < tx.max()\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m ix_marker = [\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m cpm[\u001b[33m\"\u001b[39m\u001b[33mtime_stamps\u001b[39m\u001b[33m\"\u001b[39m][mmsk]]\n\u001b[32m    624\u001b[39m df.loc[ix_marker, \u001b[33m\"\u001b[39m\u001b[33mmarker\u001b[39m\u001b[33m\"\u001b[39m] = cpm[\u001b[33m\"\u001b[39m\u001b[33mtime_series\u001b[39m\u001b[33m\"\u001b[39m][mmsk, \u001b[32m0\u001b[39m]\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# markers only if left over (in case the LFP/ECOG data stream aborted)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:1439\u001b[39m, in \u001b[36margmin\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m   1350\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1351\u001b[39m \u001b[33;03mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[32m   1352\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1436\u001b[39m \u001b[33;03m(2, 1, 4)\u001b[39;00m\n\u001b[32m   1437\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1438\u001b[39m kwds = {\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/base.py:789\u001b[39m, in \u001b[36mIndexOpsMixin.argmin\u001b[39m\u001b[34m(self, axis, skipna, *args, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate.argmin()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     result = \u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanargmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result == -\u001b[32m1\u001b[39m:\n\u001b[32m    791\u001b[39m         warnings.warn(\n\u001b[32m    792\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe behavior of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.argmax/argmin \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    793\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwith skipna=False and NAs, or with all-NAs is deprecated. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    796\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m    797\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/nanops.py:1193\u001b[39m, in \u001b[36mnanargmin\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m   1155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnanargmin\u001b[39m(\n\u001b[32m   1156\u001b[39m     values: np.ndarray,\n\u001b[32m   1157\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     mask: npt.NDArray[np.bool_] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1161\u001b[39m ) -> \u001b[38;5;28mint\u001b[39m | np.ndarray:\n\u001b[32m   1162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1163\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[33;03m    ----------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1191\u001b[39m \u001b[33;03m    array([0, 0, 1, 1])\u001b[39;00m\n\u001b[32m   1192\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1193\u001b[39m     values, mask = \u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value_typ\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m+inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1194\u001b[39m     result = values.argmin(axis)\n\u001b[32m   1195\u001b[39m     \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_arg_null_out\" has incompatible type \"Any |\u001b[39;00m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;66;03m# signedinteger[Any]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/nanops.py:294\u001b[39m, in \u001b[36m_get_values\u001b[39m\u001b[34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03mUtility to get the values view, mask, dtype, dtype_max, and fill_value.\u001b[39;00m\n\u001b[32m    262\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m    Mask for values, if deemed necessary to compute\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# In _get_values is only called from within nanops, and in all cases\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m#  with scalar fill_value.  This guarantee is important for the\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m#  np.where call below\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m mask = \u001b[43m_maybe_get_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m dtype = values.dtype\n\u001b[32m    298\u001b[39m datetimelike = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/nanops.py:248\u001b[39m, in \u001b[36m_maybe_get_mask\u001b[39m\u001b[34m(values, skipna, mask)\u001b[39m\n\u001b[32m    245\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m skipna \u001b[38;5;129;01mor\u001b[39;00m values.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m         mask = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:207\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np.ndarray, ABCExtensionArray)):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._can_hold_na:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuro/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:300\u001b[39m, in \u001b[36m_isna_array\u001b[39m\u001b[34m(values, inf_as_na)\u001b[39m\n\u001b[32m    298\u001b[39m         result = ~np.isfinite(values)\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "raws = create_raws_from_mat_and_xdf(xdf_files, day=\"day3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing block4_copydraw_on.xdf\n",
      "Failed for block4_copydraw_on.xdf: file block4_copydraw_on.xdf does not exist.\n",
      "Processing block3_copydraw_off.xdf\n",
      "Failed for block3_copydraw_off.xdf: file block3_copydraw_off.xdf does not exist.\n",
      "Processing block12_copydraw_on.xdf\n",
      "Failed for block12_copydraw_on.xdf: file block12_copydraw_on.xdf does not exist.\n",
      "Processing block6_copydraw_on.xdf\n",
      "Failed for block6_copydraw_on.xdf: file block6_copydraw_on.xdf does not exist.\n",
      "Processing block5_copydraw_off.xdf\n",
      "Failed for block5_copydraw_off.xdf: file block5_copydraw_off.xdf does not exist.\n",
      "Processing block7_copydraw_off.xdf\n",
      "Failed for block7_copydraw_off.xdf: file block7_copydraw_off.xdf does not exist.\n",
      "Processing block11_copydraw_off.xdf\n",
      "Failed for block11_copydraw_off.xdf: file block11_copydraw_off.xdf does not exist.\n",
      "Processing block2_copydraw_on.xdf\n",
      "Failed for block2_copydraw_on.xdf: file block2_copydraw_on.xdf does not exist.\n",
      "Processing block8_copydraw_on.xdf\n",
      "Failed for block8_copydraw_on.xdf: file block8_copydraw_on.xdf does not exist.\n",
      "Processing block1_copydraw_off.xdf\n",
      "Failed for block1_copydraw_off.xdf: file block1_copydraw_off.xdf does not exist.\n",
      "Processing block10_copydraw_on.xdf\n",
      "Failed for block10_copydraw_on.xdf: file block10_copydraw_on.xdf does not exist.\n",
      "Processing block9_copydraw_off.xdf\n",
      "Failed for block9_copydraw_off.xdf: file block9_copydraw_off.xdf does not exist.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'stem'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m xdf_files = get_xdf_files(day=\u001b[33m'\u001b[39m\u001b[33mday3\u001b[39m\u001b[33m'\u001b[39m, paradigms=\u001b[33m'\u001b[39m\u001b[33mlsl\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# The 'day' parameter in create_raws_from_mat_and_xdf seems to be used for handling\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# session-specific alignment issues. We'll use a placeholder value for now.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m raws = \u001b[43mcreate_raws_from_mat_and_xdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdf_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mday3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Using 'day3' as per function's default logic\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# For demonstration, let's concatenate all blocks into a single Raw object\u001b[39;00m\n\u001b[32m      8\u001b[39m raw = mne.concatenate_raws(raws)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:1036\u001b[39m, in \u001b[36mcreate_raws_from_mat_and_xdf\u001b[39m\u001b[34m(files, day)\u001b[39m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# add meta col\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files):\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     ao_data[i][\u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\n\u001b[32m   1038\u001b[39m chs = [\n\u001b[32m   1039\u001b[39m     c\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ao_data[\u001b[32m0\u001b[39m].columns\n\u001b[32m   1041\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mLFP\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mECOG\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mEOG\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1042\u001b[39m ]\n\u001b[32m   1043\u001b[39m info = mne.create_info(\n\u001b[32m   1044\u001b[39m     chs,\n\u001b[32m   1045\u001b[39m     \u001b[32m22_000\u001b[39m,\n\u001b[32m   1046\u001b[39m     ch_types=\u001b[33m\"\u001b[39m\u001b[33meeg\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1047\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'stem'"
     ]
    }
   ],
   "source": [
    "# The 'day' parameter in create_raws_from_mat_and_xdf seems to be used for handling\n",
    "# session-specific alignment issues. We'll use a placeholder value for now.\n",
    "# Using 'day3' as per function's default logic\n",
    "\n",
    "# For demonstration, let's concatenate all blocks into a single Raw object\n",
    "raw = mne.concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Explore the `mne.Raw` Object\n",
    "\n",
    "The loaded data is now in an `mne.Raw` object. MNE-Python provides a rich interface for exploring this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Channel names: {raw.ch_names}\")\n",
    "print(f\"Number of channels: {len(raw.ch_names)}\")\n",
    "print(f\"Sampling frequency: {raw.info['sfreq']} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Visualize Raw Data and Events\n",
    "\n",
    "Let's plot the raw time series data. We can also visualize the event markers, which are stored as `Annotations` in the `mne.Raw` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data (it's interactive!)\n",
    "# We'll select a subset of channels and a short duration for clarity\n",
    "picks = mne.pick_channels(raw.ch_names, include=[\"LFP_1\", \"LFP_2\", \"ECOG_1\", \"ECOG_2\"])\n",
    "raw.plot(start=0, duration=10, picks=picks, n_channels=4, scalings=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The event markers are stored in raw.annotations\n",
    "print(raw.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Extract and Visualize Stylus Tracing Data\n",
    "\n",
    "The stylus (tracing) coordinates are stored in a separate stream within the XDF file. We need to load the XDF file again with `pyxdf` to access all streams and find the one containing the stylus data. Based on the task (CopyDraw), we can look for a stream with a name related to drawing or mouse coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the first XDF file from the session for this example\n",
    "xdf_file_path = xdf_files[0]\n",
    "streams, header = pyxdf.load_xdf(xdf_file_path)\n",
    "\n",
    "stylus_stream = None\n",
    "for stream in streams:\n",
    "    # Heuristic to find the stylus stream: it might be named 'Mouse' or similar,\n",
    "    # and will likely have 2 or 3 channels (X, Y, maybe pressure).\n",
    "    stream_name = stream[\"info\"][\"name\"][0]\n",
    "    if (\n",
    "        \"Mouse\" in stream_name\n",
    "        or \"Stylus\" in stream_name\n",
    "        or \"Coordinates\" in stream_name\n",
    "    ):\n",
    "        stylus_stream = stream\n",
    "        break\n",
    "\n",
    "if stylus_stream:\n",
    "    print(f\"Found stylus stream: {stylus_stream['info']['name'][0]}\")\n",
    "    stylus_data = stylus_stream[\"time_series\"]\n",
    "    stylus_timestamps = stylus_stream[\"time_stamps\"]\n",
    "\n",
    "    # Create a pandas DataFrame for easier handling\n",
    "    df_stylus = pd.DataFrame(stylus_data, columns=[\"x\", \"y\"])  # Assuming 2D coordinates\n",
    "    df_stylus[\"time\"] = stylus_timestamps\n",
    "\n",
    "    # Plot the stylus trace\n",
    "    fig = px.line(df_stylus, x=\"x\", y=\"y\", title=\"Stylus Trace\")\n",
    "    fig.update_yaxes(autorange=\"reversed\")  # Often, screen Y coordinates are inverted\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Could not automatically find a stylus/mouse stream in the XDF file.\")\n",
    "    print(\"Available streams:\")\n",
    "    for stream in streams:\n",
    "        print(f\"- {stream['info']['name'][0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
