{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing and Epoching\n",
    "\n",
    "This notebook continues from the data loading step and guides you through the preprocessing pipeline described in the project overview. The goal is to clean the raw data and structure it for model training.\n",
    "\n",
    "The steps include:\n",
    "- DBS artifact removal (conceptual outline)\n",
    "- Downsampling\n",
    "- Filtering (band-pass and notch)\n",
    "- Common Average Referencing (CAR)\n",
    "- Source Power Comodulation (SPoC) for spatial filtering\n",
    "- Epoching into 1-second segments\n",
    "- Calculating tracing speed from stylus data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setup and Data Loading\n",
    "\n",
    "We start by importing the necessary libraries and loading the data, just as in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m session_folder = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./data/data_p00\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     17\u001b[39m xdf_files = get_xdf_files(session_folder)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m raws = \u001b[43mcreate_raws_from_mat_and_xdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdf_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mday3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m raw = mne.concatenate_raws(raws)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# We'll work with a copy to keep the original data intact\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/latent-neural-dynamics-modeling/analysis_scripts/load_xdf.py:1040\u001b[39m, in \u001b[36mcreate_raws_from_mat_and_xdf\u001b[39m\u001b[34m(files, day)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files):\n\u001b[32m   1036\u001b[39m     ao_data[i][\u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m] = fname.stem\n\u001b[32m   1038\u001b[39m chs = [\n\u001b[32m   1039\u001b[39m     c\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mao_data\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.columns\n\u001b[32m   1041\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mLFP\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mECOG\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mEOG\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1042\u001b[39m ]\n\u001b[32m   1043\u001b[39m info = mne.create_info(\n\u001b[32m   1044\u001b[39m     chs,\n\u001b[32m   1045\u001b[39m     \u001b[32m22_000\u001b[39m,\n\u001b[32m   1046\u001b[39m     ch_types=\u001b[33m\"\u001b[39m\u001b[33meeg\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1047\u001b[39m )\n\u001b[32m   1048\u001b[39m raws = []\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import mne\n",
    "import pyxdf\n",
    "\n",
    "# Add the analysis_scripts directory to the Python path\n",
    "sys.path.append(str(Path.cwd().parent.parent / \"analysis_scripts\"))\n",
    "\n",
    "from load_xdf import get_xdf_files, create_raws_from_mat_and_xdf\n",
    "\n",
    "# Load the data again\n",
    "session_id = \"S003\"  # Example session\n",
    "session_folder = f\"./data/data_p00{session_id[-1]}/\"\n",
    "xdf_files = get_xdf_files(session_folder)\n",
    "raws = create_raws_from_mat_and_xdf(xdf_files, day=\"day3\")\n",
    "raw = mne.concatenate_raws(raws)\n",
    "\n",
    "# We'll work with a copy to keep the original data intact\n",
    "raw_processed = raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 DBS Artifact Removal (Conceptual)\n",
    "\n",
    "The project description mentions using a template subtraction method for removing DBS artifacts in ON-state recordings. This is a crucial but complex step that requires a precise template of the stimulation artifact.\n",
    "\n",
    "The process generally involves:\n",
    "1.  **Identifying stimulation pulse timings:** This could come from a separate marker stream or be detected from the signal itself.\n",
    "2.  **Creating an artifact template:** Averaging the signal epochs locked to the stimulation pulses.\n",
    "3.  **Subtracting the template:** Subtracting the averaged template from the signal at each pulse time.\n",
    "\n",
    "Implementing this is highly specific to the data and stimulation parameters. Below is a conceptual function. You would need to replace it with a proper implementation (e.g., based on the cited papers by Hammer et al., 2022; Qian et al., 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dbs_artifact(raw, stim_freq):\n",
    "    \"\"\"Placeholder function for DBS artifact removal.\"\"\"\n",
    "    print(\"Applying conceptual DBS artifact removal...\")\n",
    "    # In a real implementation, you would find stim events,\n",
    "    # create a template, and subtract it.\n",
    "    # For now, this function does nothing to the data.\n",
    "    return raw\n",
    "\n",
    "\n",
    "# Apply to DBS-ON blocks if applicable (this requires identifying those blocks)\n",
    "# For now, we apply it conceptually to the whole recording.\n",
    "raw_processed = remove_dbs_artifact(\n",
    "    raw_processed, stim_freq=130\n",
    ")  # Assuming a 130Hz stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Downsampling\n",
    "\n",
    "The original data is sampled at 22 kHz, which is very high. We downsample it to 1000 Hz to make it more manageable and to match the frequency range of interest for most neural signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original sampling frequency: {raw_processed.info['sfreq']} Hz\")\n",
    "raw_processed.resample(1000, npad=\"auto\")\n",
    "print(f\"New sampling frequency: {raw_processed.info['sfreq']} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Filtering\n",
    "\n",
    "We apply two types of filters:\n",
    "1.  **Band-pass filter (3-250 Hz):** This removes very low-frequency drifts and high-frequency noise outside our range of interest.\n",
    "2.  **Notch filter (50 Hz and harmonics):** This removes power-line noise, which is a common source of contamination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply band-pass filter\n",
    "raw_processed.filter(l_freq=3.0, h_freq=250.0, fir_design=\"firwin\")\n",
    "\n",
    "# Apply notch filter for power-line noise\n",
    "notch_freqs = np.arange(50, 251, 50)\n",
    "raw_processed.notch_filter(freqs=notch_freqs, fir_design=\"firwin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Common Average Reference (CAR)\n",
    "\n",
    "CAR is a re-referencing technique that helps reduce common-mode noise across all channels. It works by subtracting the average signal of all electrodes from each individual electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CAR. We'll apply it to ECOG and LFP channels separately.\n",
    "raw_processed.set_eeg_reference(\"average\", projection=True, ch_type=\"ecog\")\n",
    "raw_processed.set_eeg_reference(\n",
    "    \"average\", projection=True, ch_type=\"dbs\"\n",
    ")  # 'dbs' for LFP\n",
    "raw_processed.apply_proj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Source Power Comodulation (SPoC)\n",
    "\n",
    "SPoC is a spatial filtering technique used to find components whose power comodulates with a target variable (e.g., task performance, movement speed). It's a supervised method that needs a target variable `y` to be fitted.\n",
    "\n",
    "Here, we'll outline the steps. To run it, you would need to define a target variable that aligns with your data. For example, you could use periods of high vs. low tracing speed as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import SPoC\n",
    "\n",
    "# 1. Define a target variable `y`. This is the trickiest part.\n",
    "#    `y` should be a continuous variable of the same length as the data,\n",
    "#    representing the signal you want to isolate (e.g., tracing speed).\n",
    "#    Here, we'll create a placeholder `y`.\n",
    "y = np.random.randn(len(raw_processed.times))\n",
    "\n",
    "# 2. Initialize the SPoC transformer\n",
    "spoc = SPoC(n_components=4, reg=\"ledoit_wolf\", rank=\"full\")\n",
    "\n",
    "# 3. Fit SPoC to the data. This finds the spatial filters.\n",
    "#    Note: SPoC is often fitted on epoched data, but can be used on continuous data.\n",
    "#    We will fit it on the continuous data here for simplicity.\n",
    "print(\"Fitting SPoC... (this may take a while)\")\n",
    "# spoc.fit(raw_processed.get_data(), y) # This would be the actual call\n",
    "print(\n",
    "    \"Conceptual SPoC fitting complete. In a real scenario, you would now use spoc.transform()\"\n",
    ")\n",
    "\n",
    "# After fitting, you would apply the transformation:\n",
    "# raw_spoc = spoc.transform(raw_processed.get_data())\n",
    "\n",
    "# For now, we will continue with the CAR-processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Epoching\n",
    "\n",
    "Now we segment the continuous, preprocessed data into 1-second epochs. This is a common step before feeding data into a machine learning model. We'll use the event markers we saw in the first notebook to define the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get events from annotations\n",
    "events, event_id = mne.events_from_annotations(raw_processed)\n",
    "\n",
    "# Create 1-second epochs, starting from the event onset\n",
    "epochs = mne.Epochs(\n",
    "    raw_processed,\n",
    "    events,\n",
    "    event_id,\n",
    "    tmin=0.0,\n",
    "    tmax=1.0,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    "    reject=None,\n",
    ")\n",
    "\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Calculate Tracing Speed\n",
    "\n",
    "Finally, let's calculate the tracing speed from the stylus coordinates. Speed is a useful behavioral variable that can be correlated with neural activity or used as a target for decoding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stylus data again (as in the first notebook)\n",
    "xdf_file_path = xdf_files[0]\n",
    "streams, header = pyxdf.load_xdf(xdf_file_path)\n",
    "stylus_stream = next((s for s in streams if \"Mouse\" in s[\"info\"][\"name\"][0]), None)\n",
    "\n",
    "if stylus_stream:\n",
    "    df_stylus = pd.DataFrame(stylus_stream[\"time_series\"], columns=[\"x\", \"y\"])\n",
    "    df_stylus[\"time\"] = stylus_stream[\"time_stamps\"]\n",
    "\n",
    "    # Calculate differences in position and time\n",
    "    df_stylus[\"dx\"] = df_stylus[\"x\"].diff()\n",
    "    df_stylus[\"dy\"] = df_stylus[\"y\"].diff()\n",
    "    df_stylus[\"dt\"] = df_stylus[\"time\"].diff()\n",
    "\n",
    "    # Calculate speed\n",
    "    df_stylus[\"speed\"] = (\n",
    "        np.sqrt(df_stylus[\"dx\"] ** 2 + df_stylus[\"dy\"] ** 2) / df_stylus[\"dt\"]\n",
    "    )\n",
    "    df_stylus = df_stylus.dropna()\n",
    "\n",
    "    # Plot the speed over time\n",
    "    fig = px.line(df_stylus, x=\"time\", y=\"speed\", title=\"Stylus Tracing Speed\")\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Could not find stylus stream to calculate speed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
