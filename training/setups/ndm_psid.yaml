model:
  name: "psid_neural"
  use_behavioral_input: false
  n_states: 20            # latent dimensionality
  past_horizon: 10        # block rows for past Hankel
  future_horizon: 10      # block rows for future Hankel
  rank_n: 20              # rank for state subspace
  alpha: 0.01             # regularization for least squares steps
  # Optional toggles
  stable_A: true          # project A to stable if supported in your PSID impl
  estimate_noise: false   # skip noise model if not needed

data:
  root_dir: "resampled_recordings"
  participants: "{data.root_dir}/participants"
  split:
    enabled: true
    seed: 42
    split_type: "time"
    min_train_epochs: 120
    val_size: 0.1
    test_size: 0.1
  batch_size: 32
  num_workers: 4
  shuffle: true
  x_key: "neural"         # features (neural)
  y_key: "neural"         # outputs to predict (self-prediction/forecast)

training:
  epochs: 100
  learning_rate: 0.001
  optimizer: "adam"
  weight_decay: 0.0001
  scheduler:
    type: "StepLR"
    step_size: 30
    gamma: 0.1
  device: "cuda"
  seed: 42
  # Early stopping hooks (optional)
  early_stopping:
    enabled: true
    metric: "val_loss"
    patience: 10
    mode: "min"

results:
  save_dir: "results/{model.name}"
  model_name: "{model.name}_model"
  save_frequency: 10
  checkpoint_dir: "{results.save_dir}/checkpoints"
  log_dir: "{results.save_dir}/logs"
  tensorboard_dir: "{results.save_dir}/tensorboard"
  train_file: "{results.save_dir}/split/train.parquet"
  val_file: "{results.save_dir}/split/val.parquet"
  test_file: "{results.save_dir}/split/test.parquet"

# Hyperparameter search space (grid or random can be implemented in your runner)
search:
  enabled: true
  strategy: "grid"          # "grid" or "random"
  max_trials: 50            # used for random; ignored for pure grid
  params:
    model.n_states: [8, 12, 16, 20, 24]
    model.past_horizon: [5, 10, 15]
    model.future_horizon: [5, 10, 15]
    model.rank_n: [8, 12, 16, 20]
    model.alpha: [0.0, 0.001, 0.01, 0.1]
    training.learning_rate: [0.0003, 0.001, 0.003]
    training.weight_decay: [0.0, 0.0001, 0.001]
  objective:
    metric: "val_loss"
    mode: "min"
  # Optional constraints to keep combinations valid
  constraints:
    - type: "less_or_equal"
      left: "model.rank_n"
      right: "model.n_states"